{"cells":[{"cell_type":"markdown","metadata":{"id":"Ojo7-fuGwugp"},"source":["# CLUSTERING\n","\n","Monitor: Juan Nicolas Piedrahita Salas\n","\n","Introduccion a la inteligencia artificial 2023-01\n","\n","## Importar librerias necesarias"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1679194051346,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"7Wn0T0VOwugs"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"d7Mqite-wugu"},"source":["## Lectura de datos\n","\n","#### este datset contiene informacion actualizada al 2021 sobre jugadores de la premier league\n","\n","la limpieza de datos de este dataset fue realizada previamente, por lo que los datos vienen listos para usar (se deberian haber limpiado valores atipicos sin embargo no se hizo para mostrar sus efectos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1679194051571,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"eL3mo_Xgwugu","outputId":"94c1da62-3d2d-481c-8344-843ce60d440c"},"outputs":[],"source":["# Cargamos el dataset\n","datos = pd.read_csv(\"premier_league_2021_players.csv\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"N1t9URxUwugv"},"source":["## exploracion de los datos"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### estadisticas basicas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1679194051842,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"HznmHiOkwugv","outputId":"906f44d5-b40c-440c-83fd-e33181a64cda"},"outputs":[],"source":["datos.describe()"]},{"cell_type":"markdown","metadata":{"id":"N6hOWqiTwugw"},"source":["podemos graficar las distribuciones y correlaciones de los datos, para tener una idea de como se comportan"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1679194051844,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"JQPHCHXnwugw"},"outputs":[],"source":["# funcion para graficar la correlacion y la distribucion entre variables numericas\n","def plot_pares(df):\n","    import matplotlib.pyplot as plt\n","    import seaborn as sb\n","    import numpy as np\n","\n","    num_cols = df.select_dtypes(include=np.number).columns\n","\n","    # matriz de correlaciones\n","    grid = sb.pairplot(\n","        df,\n","        height=2, \n","        vars=num_cols,\n","        kind='scatter'\n","    )\n","\n","    def pintarCorr(x, y, **kwargs):\n","        plt.gca().get_children()[0].remove()\n","\n","        # calcular correlacion de pearson\n","        corr = round(np.corrcoef(x, y)[0,1], 2)\n","        plt.gca().text((max(x) + min(x))/2, (max(y) + min(y))/2, s=str(corr), fontsize=12)\n","\n","\n","    # pintar la correlacion en la parte inferior de la diagonal\n","    grid.map_lower(pintarCorr)\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":29894,"status":"ok","timestamp":1679194081731,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"X9d46HyEwugx","outputId":"98321e9c-ab18-414c-a771-dc52a90c160c"},"outputs":[],"source":["plot_pares(datos)"]},{"cell_type":"markdown","metadata":{"id":"qMLy6f-Rwugx"},"source":["la grafica nos muestra graficos por pares, las distribuciones y las correlaciones lineales de las variables numericas, este grafico nos permite entender como se relacionan las variables entre si"]},{"cell_type":"markdown","metadata":{"id":"PqT5sFAQwugy"},"source":["#### escalamos las datos para que esten en el mismo rango [0, 1]\n","para todos los algoritmos basados en distancias debemos escalar los datos al mismo rango, para evitar que hayan variables que tengan mayor influencia a la hora de calcular las distancias entre puntos, en este caso usaremos `MinMaxScaler` de la libreria `sklearn`\n","\n","en este ejemplo escogeremos 3 columnas para hacer el clustering, de modo que las podamos graficar en un grafico 3D"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1679194081732,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"HMDESGHgwugy","outputId":"03e12b0f-805b-4d23-ad07-fc2ecc002689"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n"]},{"cell_type":"markdown","metadata":{"id":"Thf0VTfnwugz"},"source":["### evaluamos la cantidad optima de clusters"]},{"cell_type":"markdown","metadata":{"id":"FEzBeC29wugz"},"source":["#### elbow curve"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1679194081732,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"dFxIKZIYwugz"},"outputs":[],"source":["def elbow_curve(data, maxClusters = 15):\n","  from sklearn.cluster import KMeans\n","  \n","  # rango de valores del parámetro a optimizar (cantidad de clusters)\n","  maxClusters = range(1, maxClusters + 1)\n","\n","  # se ejecuta el modelo para el rango de clusters y se guarda la inercia\n","  # respectiva obtenida para cada valor\n","  inertias = []\n","  for k in maxClusters:\n","    kmeanModel = KMeans(n_clusters = k, n_init=\"auto\")\n","    kmeanModel.fit(data)\n","    inertias.append(kmeanModel.inertia_)\n","\n","  # Grafico de los resultados obtenidos para cada valor del rango\n","  plt.plot(maxClusters, inertias, 'bx-')\n","  plt.xlabel('k')\n","  plt.ylabel('Inertia')\n","  plt.title('Curva de codo')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":795,"status":"ok","timestamp":1679194082520,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"QCZNut_Wwug0","outputId":"4305e1ee-3601-4abf-8c8d-76e24da994c5"},"outputs":[],"source":["elbow_curve(scaled_data)"]},{"cell_type":"markdown","metadata":{"id":"QBXgPoY3wug0"},"source":["#### Estadistico de GAP"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":197,"status":"ok","timestamp":1679194107203,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"vrzlEcZywug1"},"outputs":[],"source":["# nrefs es la cantidad de datos (\"datasets\") de referencia contra los que se va a comparar\n","def GAPstatistic(data, maxClusters=15, nrefs=3):\n","    from sklearn.cluster import KMeans\n","    \n","    gaps = np.zeros((maxClusters,))\n","    results = {'clusterCount':[], 'gap':[]}\n","    for gap_index, k in enumerate(range(1, maxClusters+1)):\n","\n","        # guardara los resultados de dispersión de cada distribución simulada\n","        refDisps = np.zeros(nrefs)\n","\n","        # Genera las muestras aleatorias indicadas con nrefs y ejecuta k-means\n","        # en cada bucle obteniendo los resultados de dispersión (inercia)\n","        # para cada conjunto generado.\n","        for i in range(nrefs):\n","            \n","            # Crea nuevo conjunto aleatorio de referencia\n","            # Se puede usar una semilla para tener reproducibilidad\n","            np.random.seed(0)\n","            randomReference = np.random.random_sample(size=data.shape)\n","            \n","            # se ajusta el modelo al conjunto de referencia\n","            km = KMeans(k, n_init=\"auto\")\n","            km.fit(randomReference)\n","            # se guarda la dispersión obtenida\n","            refDisp = km.inertia_\n","            refDisps[i] = refDisp\n","\n","        # Se ajusta el modelo a los datos originales y se guarda su inercia\n","        km = KMeans(k, n_init=\"auto\")\n","        km.fit(data)\n","        \n","        origDisp = km.inertia_\n","\n","        # Calcula el estadístico de gap para k clusters usando el promedio de\n","        # las dispersiones de los datos simulados y la dispersión de los datos originales.\n","        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n","\n","        # Guarda el estadístico de gap obtenido en este bucle.\n","        gaps[gap_index] = gap\n","        \n","        results['clusterCount'].append(k)\n","        results['gap'].append(gap)\n","\n","    # Selecciona el \"primer máximo\" de los estadísticos obtenidos y devuelve \n","    # su respectivo número de clusters  \n","    optK = 0  \n","    for i in range(0, len(gaps)-1):\n","      if gaps[i+1] <= gaps[i]:\n","        optK = i+1\n","        break\n","    \n","    plt.figure()\n","\n","    plt.plot(results['clusterCount'], results['gap'], linewidth=3, marker='o')\n","    plt.axvline(x=optK, color='r', linestyle='--')\n","\n","    plt.xlabel('Cantidad de clusters')\n","    plt.ylabel('Gap')\n","    plt.title('Estadístico de gap')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":1416,"status":"ok","timestamp":1679194108853,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"cA-rAn4gwug1","outputId":"3e962aeb-e96f-4d3a-c20a-0614203e0cf1"},"outputs":[],"source":["GAPstatistic(scaled_data)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y-bjdNmGwug2"},"source":["#### Coeficiente de silueta\n","\n","[documentacion sobre este metodo](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def coef_silueta(data, maxClusters=6):\n","    from sklearn.cluster import KMeans\n","    from sklearn.metrics import silhouette_samples, silhouette_score\n","    import matplotlib.cm as cm\n","\n","    for n_clusters in range(2, maxClusters+1):\n","        # Create a subplot with 1 row and 2 columns\n","        fig, (ax1, ax2) = plt.subplots(1, 2)\n","        fig.set_size_inches(19, 4)\n","\n","        # The 1st subplot is the silhouette plot\n","        # The silhouette coefficient can range from -1, 1 but in this example all\n","        # lie within [-0.1, 1]\n","        ax1.set_xlim(-0.1, 1)\n","        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","        # plots of individual clusters, to demarcate them clearly.\n","        ax1.set_ylim(0, len(data) + (n_clusters + 1) * 10)\n","\n","        # Initialize the clusterer with n_clusters value and a random generator\n","        # seed of 10 for reproducibility.\n","        clusterer = KMeans(n_clusters=n_clusters, random_state=10, n_init=\"auto\")\n","        cluster_labels = clusterer.fit_predict(data)\n","        \n","        # The silhouette_score gives the average value for all the samples.\n","        # This gives a perspective into the density and separation of the formed\n","        # clusters\n","        silhouette_avg = silhouette_score(data, cluster_labels)\n","        print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n","\n","        # Compute the silhouette scores for each sample\n","        sample_silhouette_values = silhouette_samples(data, cluster_labels)\n","\n","        y_lower = 10\n","        for i in range(n_clusters):\n","            # Aggregate the silhouette scores for samples belonging to\n","            # cluster i, and sort them\n","            ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n","\n","            ith_cluster_silhouette_values.sort()\n","\n","            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","            y_upper = y_lower + size_cluster_i\n","\n","            color = cm.nipy_spectral(float(i) / n_clusters)\n","            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n","                            0, ith_cluster_silhouette_values,\n","                            facecolor=color, edgecolor=color, alpha=0.7)\n","\n","            # Label the silhouette plots with their cluster numbers at the middle\n","            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","            # Compute the new y_lower for next plot\n","            y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","        ax1.set_title(\"The silhouette plot for the various clusters.\")\n","        ax1.set_xlabel(\"The silhouette coefficient values\")\n","        ax1.set_ylabel(\"Cluster label\")\n","\n","        # The vertical line for average silhouette score of all the values\n","        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n","        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","        # 2nd Plot showing the actual clusters formed\n","        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n","        ax2.scatter(data[:, 0], data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n","                    c=colors, edgecolor='k')\n","\n","        # Labeling the clusters\n","        centers = clusterer.cluster_centers_\n","        # Draw white circles at cluster centers\n","        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n","                    c=\"white\", alpha=1, s=200, edgecolor='k')\n","\n","        for i, c in enumerate(centers):\n","            ax2.scatter(c[0], c[1], marker=f\"${i}$\", alpha=1,\n","                        s=50, edgecolor='k')\n","\n","        ax2.set_title(\"The visualization of the clustered data.\")\n","        ax2.set_xlabel(\"Feature space for the 1st feature\")\n","        ax2.set_ylabel(\"Feature space for the 2nd feature\")\n","\n","        plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n","                    \"with n_clusters = %d\" % n_clusters),\n","                    fontsize=14, fontweight='bold')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coef_silueta(scaled_data)"]},{"cell_type":"markdown","metadata":{"id":"VSruC0fxwug2"},"source":["### Dendograma"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1679194108854,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"pdkoN30Zwug2"},"outputs":[],"source":["def Dendograma(data, lines=[]):\n","    import scipy.cluster.hierarchy as shc\n","\n","    plt.figure(figsize=(15, 7))  \n","    plt.title(\"Dendrograma\") \n","    dend = shc.dendrogram(shc.linkage(data, method='ward'),truncate_mode='level',p=3)\n","\n","    for l in lines:\n","        plt.axhline(y=l, color='b', linestyle='-.')\n","    \n","    plt.ylabel('Distancia euclidiana')\n","    plt.xlabel('puntos de datos')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1679194109358,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"moIwild-wug3","outputId":"f4dbbc91-9ee3-44c8-c556-dfde84ed0bb2"},"outputs":[],"source":["Dendograma(scaled_data, )"]},{"cell_type":"markdown","metadata":{"id":"l3UHGU2Pwug3"},"source":["### clustering jerarquico aglomerativo\n","\n","usaremos la clase `AgglomerativeClustering` de la libreria `sklearn`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1679194109359,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"Vdn22uyHwug3"},"outputs":[],"source":["from sklearn.cluster import AgglomerativeClustering\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lo9yigwewug3"},"source":["### clustering k-means\n","\n","usaremos la clase `KMeans` de la libreria `sklearn`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1679194109360,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"y_A5CxhRwug3"},"outputs":[],"source":["from sklearn.cluster import KMeans\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Kr8d6aiwwug4"},"source":["### comparacion entre metodos\n","\n","jugadores que fueron clasificados diferentes po cada metodo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1679194109361,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"NqiIfSPywug4","outputId":"11fac49e-e074-43c7-f2be-d3214968a7f6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_KxhOyEOwug4"},"source":["conteo por clase"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1679194109361,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"S4CqKdP-wug4","outputId":"098fb2af-0f67-4e6b-ecf8-88c20eb4b33a"},"outputs":[],"source":["display(\n","\n",")"]},{"cell_type":"markdown","metadata":{"id":"ukYT_SoQwug5"},"source":["### Caracterizacion de los datos por cluster"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### grafico 3D"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1486,"status":"ok","timestamp":1679194110830,"user":{"displayName":"Juan Nicolas Piedrahita Salas","userId":"13233370715309287259"},"user_tz":300},"id":"Mn7KfPd_wug5","outputId":"e40dab0a-14ec-4151-a449-ff710ac14a74"},"outputs":[],"source":["from plotly.express import scatter_3d\n","\n","datos[\"cluster\"] = aggClusters.labels_\n","\n","fig = scatter_3d(\n","    datos,\n","    x=\"\",\n","    y=\"\",\n","    z=\"\",\n","    color=\"cluster\",\n",")\n","\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### graficar la media de cada variable por cluster"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Podemos ver un las estadisticas de un jugador en especifico"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtro = datos[\"Name\"].str.contains(\"\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### ejemplos de jugadores por cluster\n","\n","mostrar los nombres de los 5 primeros jugadores de cada cluster"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### ejemplos de jugador por cluster y posicion\n","\n","mostrar los nombres de los primeros 5 jugadores agrupados por cluster y posicion"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### prediccion de cluster de un nuevo jugador\n","\n","##### para predecir el cluster de un nuevo jugador debemos seguir los mismos pasos que para el clustering, es decir, escalar los datos y aplicar el algoritmo de clustering\n","\n","no podemos hacer predicciones con el metodo aglomerativo, ya que el añadir un nuevo punto, puede cambiar completamente el como se generan los clusters en este metodo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["jugador_nuevo = pd.DataFrame({\"\": np.random.uniform(0, 180), \"\": np.random.uniform(0, 80), \"\": np.random.uniform(0, 18000)}, index=[0])\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
